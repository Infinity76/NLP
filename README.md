# NLP

Tokenize every book and produce orderly datasets that use stop words Using stop words and the unnest tokens command, the author created tidy data sets for each book. After determining proportions, the four datasets were stacked using the bind rows function, and frequency counts of the word distributions were generated. James Joyce served as the model when constructing the word frequency plots for each of the three authors. Use the tidy dataset from James Joyce to perform sentiment analysis on the positive and negative words, compute the correlations between James Joyce and each of the other three authors, and more.
